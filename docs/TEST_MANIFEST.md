# Komorebi Test Manifest

This document provides a comprehensive overview of all tests in the Komorebi project, including:
- **Automated Tests** - Unit tests, integration tests, and benchmarks
- **Human Tests** - Manual verification procedures for confirming functionality

## Test Infrastructure

### Test Framework
- **pytest** (>=7.4.0) - Python testing framework
- **pytest-asyncio** (>=0.23.0) - Async test support
- **pytest-httpx** (>=0.28.0) - HTTP mocking for tests

### Running Tests

```bash
# Run all tests
python -m pytest

# Run with verbose output
python -m pytest -v

# Run specific test file
python -m pytest backend/tests/test_api.py

# Run specific test class
python -m pytest backend/tests/test_models.py::TestChunkModels

# Run specific test
python -m pytest backend/tests/test_api.py::test_create_chunk
```

---

## Test Files

### `backend/tests/test_models.py`

Tests for Pydantic data models. These tests validate the schema definitions and data validation rules.

| Test Class | Test Name | Description |
|------------|-----------|-------------|
| `TestChunkModels` | `test_chunk_create_minimal` | Verifies chunk creation with only required fields |
| `TestChunkModels` | `test_chunk_create_full` | Verifies chunk creation with all optional fields |
| `TestChunkModels` | `test_chunk_model` | Tests the full Chunk model with auto-generated fields (id, timestamps) |
| `TestChunkModels` | `test_chunk_update_partial` | Validates partial update schema (exclude_unset behavior) |
| `TestProjectModels` | `test_project_create` | Verifies project creation schema |
| `TestProjectModels` | `test_project_model` | Tests the full Project model with defaults |
| `TestMCPModels` | `test_mcp_server_config` | Validates MCP server configuration model |

### `backend/tests/test_api.py`

Integration tests for API endpoints. These tests use an async test client to make real HTTP requests against the FastAPI application.

| Test Name | Endpoint | Description |
|-----------|----------|-------------|
| `test_root_endpoint` | `GET /` | Verifies root endpoint returns service info |
| `test_health_endpoint` | `GET /health` | Validates health check endpoint |
| `test_create_chunk` | `POST /api/v1/chunks` | Tests chunk creation via API |
| `test_list_chunks` | `GET /api/v1/chunks` | Tests listing chunks with filters |
| `test_chunk_stats` | `GET /api/v1/chunks/stats` | Validates statistics endpoint |
| `test_create_project` | `POST /api/v1/projects` | Tests project creation |
| `test_list_projects` | `GET /api/v1/projects` | Validates project listing |
| `test_list_mcp_servers` | `GET /api/v1/mcp/servers` | Tests MCP server listing |
| `test_sse_status` | `GET /api/v1/sse/status` | Validates SSE status endpoint |

---

## Validation & Benchmarking

### `scripts/hammer_gen.py`

The Hammer script is the **success criteria** for the Komorebi implementation. It performs load testing and validates that the backend can handle concurrent requests.

#### Usage

```bash
# Run with defaults (50 chunks, 3 projects, 5 concurrent requests)
python scripts/hammer_gen.py

# Custom configuration
python scripts/hammer_gen.py --chunks 100 --projects 5 --concurrency 10

# Against a different server
python scripts/hammer_gen.py --base-url http://production:8000
```

#### Command Line Options

| Option | Default | Description |
|--------|---------|-------------|
| `--base-url` | `http://localhost:8000` | Backend server URL |
| `--chunks` | `50` | Number of chunks to create |
| `--projects` | `3` | Number of projects to create |
| `--concurrency` | `5` | Concurrent request limit |

#### What It Tests

1. **Health Check** - Verifies server is running
2. **Project Creation** - Creates test projects
3. **Chunk Capture** - Creates chunks with random content and tags
4. **Read Operations** - Lists chunks and retrieves statistics

#### Success Metrics

The benchmark outputs:
- Total/Successful/Failed requests
- Requests per second throughput
- Latency statistics (avg, min, max)

**Success criteria:** 0 failed requests

---

## Playwright UI Tests

End-to-end tests for the React dashboard using Playwright. See [PEDAGOGY_PLAYWRIGHT.md](./PEDAGOGY_PLAYWRIGHT.md) for detailed documentation on the testing framework.

### Running Playwright Tests

```bash
cd frontend

# Install dependencies (first time)
npm install

# Run all tests (headless)
npm test

# Run with browser visible
npm run test:headed

# Run with interactive UI
npm run test:ui

# Debug mode
npm run test:debug

# View HTML report
npm run test:report
```

### Test File: `frontend/e2e/dashboard.spec.ts`

| Test Suite | Test Name | Description |
|------------|-----------|-------------|
| **Dashboard Layout** | `should display the header with title and subtitle` | Verifies header renders correctly |
| | `should display the stats section with all stat cards` | Verifies 5 stat cards are present |
| | `should display navigation tabs` | Verifies Inbox, All Chunks, Projects tabs |
| | `should display the footer` | Verifies footer with version info |
| **Tab Navigation** | `should start with Inbox tab active` | Inbox is default active tab |
| | `should switch to All Chunks tab` | Tab switching works |
| | `should switch to Projects tab` | Tab switching works |
| | `should switch back to Inbox tab` | Return navigation works |
| **Stats Display** | `should display numeric values in stat cards` | All values are numbers |
| | `should display correct stat labels` | Labels match expected text |
| **Inbox Functionality** | `should have capture input and button` | Input elements present |
| | `should disable button when input is empty` | Form validation |
| | `should enable button when input has content` | Form validation |
| | `should capture a chunk and clear input` | Full capture flow |
| | `should show empty state when no inbox chunks` | Empty state display |
| **Chunk List** | `should display filter buttons` | 5 filter buttons present |
| | `should filter by status` | Filter switching works |
| | `should highlight active filter button` | Visual feedback |
| **Project Management** | `should display new project button` | Button present |
| | `should open create project form` | Form opens on click |
| | `should close create form on cancel` | Cancel button works |
| | `should create a new project` | Full creation flow |
| | `should disable create button when name is empty` | Form validation |
| **Integration Tests** | `should update stats after capturing a chunk` | Frontend-backend sync |
| | `should show chunk in All Chunks after capture` | Cross-tab data sync |
| **Accessibility** | `should have proper heading structure` | H1/H2 structure |
| | `should have clickable buttons` | Button accessibility |
| | `should have form inputs with placeholders` | Input accessibility |
| **Error Handling** | `should handle empty form submission gracefully` | No error on disabled submit |

### Page Object Models

Located in `frontend/e2e/fixtures.ts`:

| Page Object | Purpose |
|-------------|---------|
| `DashboardPage` | Main page navigation and layout |
| `InboxPage` | Quick capture functionality |
| `ChunkListPage` | All Chunks view with filtering |
| `ProjectListPage` | Project creation and listing |
| `ApiHelper` | Backend API interaction for test setup |

---

## Test Coverage Summary

| Category | Test File | Test Count | Status |
|----------|-----------|------------|--------|
| Models | `test_models.py` | 7 | âœ… Passing |
| API | `test_api.py` | 9 | âœ… Passing |
| Benchmark | `hammer_gen.py` | N/A | âœ… Validated |
| UI (Playwright) | `dashboard.spec.ts` | 28 | ğŸ†• New |
| **Total** | | **44+** | **Backend Passing** |

---

## Adding New Tests

### Model Tests

Add tests to `backend/tests/test_models.py`:

```python
from backend.app.models import YourModel

class TestYourModel:
    def test_your_model_creation(self):
        model = YourModel(field="value")
        assert model.field == "value"
```

### API Tests

Add tests to `backend/tests/test_api.py`:

```python
@pytest.mark.asyncio
async def test_your_endpoint(client: AsyncClient):
    response = await client.get("/api/v1/your-endpoint")
    assert response.status_code == 200
```

### Test Fixtures

The `client` fixture provides an async HTTP client for API testing:

```python
@pytest.fixture
async def client():
    await init_db()
    transport = ASGITransport(app=app)
    async with AsyncClient(transport=transport, base_url="http://test") as ac:
        yield ac
```

### Playwright UI Tests

Add tests to `frontend/e2e/dashboard.spec.ts`:

```typescript
import { test, expect } from './fixtures';

test.describe('Your Feature', () => {
  test('should do something', async ({ dashboardPage, page }) => {
    await dashboardPage.goto();
    
    // Your test logic
    await expect(page.locator('.your-element')).toBeVisible();
  });
});
```

### Adding Page Objects

Extend `frontend/e2e/fixtures.ts` with new page objects:

```typescript
class YourPage {
  constructor(private page: Page) {}

  get yourElement() {
    return this.page.locator('.your-selector');
  }

  async yourAction() {
    await this.yourElement.click();
  }
}

// Add to fixtures
export const test = base.extend<KomorebiFixtures>({
  yourPage: async ({ page }, use) => {
    await use(new YourPage(page));
  },
});
```

---

## Continuous Integration

Tests are configured in `pyproject.toml`:

```toml
[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["backend/tests"]
```

Run the full test suite before committing:

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests
python -m pytest -v

# Run benchmark
python scripts/hammer_gen.py
```

---

## Human Testing Procedures

These manual tests should be performed by a human to verify that the system works correctly end-to-end. Complete each test and check off the box when verified.

### Prerequisites Checklist

Before running human tests, ensure:

- [ ] Python 3.11+ is installed (`python --version`)
- [ ] Dependencies are installed (`pip install -e ".[dev]"`)
- [ ] No other service is running on port 8000
- [ ] You have a terminal/command prompt open

---

### HT-1: Server Startup Test

**Purpose:** Verify the backend server starts correctly.

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Run `komorebi serve` | Server starts without errors | â˜ |
| 2 | Observe terminal output | Shows "Uvicorn running on http://0.0.0.0:8000" | â˜ |
| 3 | Open browser to `http://localhost:8000` | Returns JSON with name "Komorebi" | â˜ |
| 4 | Open browser to `http://localhost:8000/health` | Returns `{"status": "healthy"}` | â˜ |
| 5 | Open browser to `http://localhost:8000/docs` | Swagger UI documentation loads | â˜ |

**Cleanup:** Press `Ctrl+C` to stop the server (keep it running for remaining tests).

---

### HT-2: CLI Capture Test

**Purpose:** Verify the CLI can capture chunks to the inbox.

*Prerequisite: Server must be running (HT-1)*

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Run `komorebi capture "Test thought from CLI"` | Shows "âœ… Captured: [id]..." with status "inbox" | â˜ |
| 2 | Run `komorebi capture "Another thought" --tags "test,manual"` | Shows success with tags | â˜ |
| 3 | Run `komorebi list` | Table shows both captured chunks | â˜ |
| 4 | Verify first chunk shows status "inbox" or "processed" | Status column displays correctly | â˜ |
| 5 | Verify second chunk shows tags "test, manual" | Tags column shows the tags | â˜ |

---

### HT-3: CLI Statistics Test

**Purpose:** Verify statistics are calculated correctly.

*Prerequisite: Complete HT-2 first*

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Run `komorebi stats` | Statistics table displays | â˜ |
| 2 | Check "Inbox" or "Processed" count | Count is â‰¥ 2 (from previous test) | â˜ |
| 3 | Check "Total" count | Total matches sum of all statuses | â˜ |

---

### HT-4: API Direct Access Test

**Purpose:** Verify the REST API works directly via curl/HTTP.

*Prerequisite: Server must be running*

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Run: `curl http://localhost:8000/api/v1/chunks/stats` | JSON with inbox, processed, compacted, archived, total | â˜ |
| 2 | Run: `curl -X POST http://localhost:8000/api/v1/chunks -H "Content-Type: application/json" -d '{"content": "API test chunk"}'` | Returns chunk JSON with id and status "inbox" | â˜ |
| 3 | Run: `curl http://localhost:8000/api/v1/chunks` | Returns array including the new chunk | â˜ |
| 4 | Run: `curl http://localhost:8000/api/v1/chunks/inbox` | Returns only inbox chunks | â˜ |

---

### HT-5: Project Management Test

**Purpose:** Verify projects can be created and managed.

*Prerequisite: Server must be running*

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Run: `curl -X POST http://localhost:8000/api/v1/projects -H "Content-Type: application/json" -d '{"name": "Test Project", "description": "For manual testing"}'` | Returns project JSON with id | â˜ |
| 2 | Copy the project `id` from the response | ID is a UUID format | â˜ |
| 3 | Run: `komorebi projects` | Table shows "Test Project" | â˜ |
| 4 | Run: `curl http://localhost:8000/api/v1/projects` | Returns array with the project | â˜ |

---

### HT-6: Chunk-to-Project Association Test

**Purpose:** Verify chunks can be associated with projects.

*Prerequisite: Complete HT-5, have a project ID*

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Run: `curl -X POST http://localhost:8000/api/v1/chunks -H "Content-Type: application/json" -d '{"content": "Chunk for project", "project_id": "<PROJECT_ID>"}'` | Chunk created with project_id set | â˜ |
| 2 | Run: `curl "http://localhost:8000/api/v1/chunks?project_id=<PROJECT_ID>"` | Returns only chunks for that project | â˜ |
| 3 | Run: `komorebi capture "CLI project chunk" --project <PROJECT_ID>` | Success message shown | â˜ |

---

### HT-7: SSE Real-Time Updates Test

**Purpose:** Verify Server-Sent Events work for real-time updates.

*Prerequisite: Server must be running*

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | In Terminal 1, run: `curl -N http://localhost:8000/api/v1/sse/events` | Connection stays open, waiting for events | â˜ |
| 2 | In Terminal 2, run: `komorebi capture "SSE test event"` | Capture succeeds | â˜ |
| 3 | Check Terminal 1 | Shows `data: {...}` with chunk.created event | â˜ |
| 4 | Press `Ctrl+C` in Terminal 1 | SSE connection closes cleanly | â˜ |

---

### HT-8: Hammer Benchmark Test

**Purpose:** Verify the system handles load correctly.

*Prerequisite: Server must be running*

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Run: `python scripts/hammer_gen.py --chunks 20 --projects 2` | Benchmark starts, shows progress | â˜ |
| 2 | Observe "Server is healthy" message | Health check passes | â˜ |
| 3 | Observe "Creating X projects" | Projects created successfully | â˜ |
| 4 | Observe "Capturing X chunks" with progress | All chunks captured | â˜ |
| 5 | Check final results | "Failed: 0" in results table | â˜ |
| 6 | Verify "âœ… All requests successful!" | Benchmark passed | â˜ |

---

### HT-9: Frontend Dashboard Test (Optional)

**Purpose:** Verify the React dashboard works correctly.

*Prerequisites: Server running, Node.js 18+ installed*

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Run: `cd frontend && npm install` | Dependencies installed | â˜ |
| 2 | Run: `npm run dev` | Vite dev server starts on port 3000 | â˜ |
| 3 | Open browser to `http://localhost:3000` | Dashboard loads with dark theme | â˜ |
| 4 | Check Stats section at top | Shows Inbox, Processed, Compacted, Archived, Total counts | â˜ |
| 5 | Click "ğŸ“¥ Inbox" tab | Shows inbox chunks (if any) | â˜ |
| 6 | Type in capture box and click "ğŸ“ Capture" | New chunk appears in list | â˜ |
| 7 | Click "ğŸ“‹ All Chunks" tab | Shows all chunks with filter buttons | â˜ |
| 8 | Click different status filters | List updates to show filtered chunks | â˜ |
| 9 | Click "ğŸ“ Projects" tab | Shows project list | â˜ |
| 10 | Click "+ New Project" and create one | Project appears in list | â˜ |

**Cleanup:** Press `Ctrl+C` to stop the frontend dev server.

---

### HT-10: Database Persistence Test

**Purpose:** Verify data persists across server restarts.

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Run: `komorebi stats` | Note the total count | â˜ |
| 2 | Stop the server (`Ctrl+C`) | Server stops | â˜ |
| 3 | Restart: `komorebi serve` | Server starts again | â˜ |
| 4 | Run: `komorebi stats` | Same total count as step 1 | â˜ |
| 5 | Run: `komorebi list` | Previous chunks still exist | â˜ |

---

### HT-11: Error Handling Test

**Purpose:** Verify the system handles errors gracefully.

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Stop the server if running | Server stopped | â˜ |
| 2 | Run: `komorebi capture "Test"` | Shows "Error: Could not connect to server" | â˜ |
| 3 | Start the server again | Server running | â˜ |
| 4 | Run: `curl http://localhost:8000/api/v1/chunks/invalid-uuid` | Returns 404 or validation error | â˜ |
| 5 | Run: `curl -X POST http://localhost:8000/api/v1/chunks -H "Content-Type: application/json" -d '{}'` | Returns 422 validation error (content required) | â˜ |

---

### HT-12: Clean Slate Test

**Purpose:** Verify the system can be reset cleanly.

| Step | Action | Expected Result | âœ“ |
|------|--------|-----------------|---|
| 1 | Stop the server | Server stopped | â˜ |
| 2 | Run: `rm komorebi.db` | Database file deleted | â˜ |
| 3 | Start server: `komorebi serve` | Server starts, creates new DB | â˜ |
| 4 | Run: `komorebi stats` | All counts are 0 | â˜ |
| 5 | Run: `komorebi list` | Shows "No chunks found" | â˜ |

---

## Human Test Summary

| Test ID | Test Name | Component | Priority |
|---------|-----------|-----------|----------|
| HT-1 | Server Startup | Backend | Critical |
| HT-2 | CLI Capture | CLI | Critical |
| HT-3 | CLI Statistics | CLI | High |
| HT-4 | API Direct Access | Backend API | Critical |
| HT-5 | Project Management | Backend API | High |
| HT-6 | Chunk-to-Project Association | Backend API | Medium |
| HT-7 | SSE Real-Time Updates | Backend SSE | Medium |
| HT-8 | Hammer Benchmark | Backend | Critical |
| HT-9 | Frontend Dashboard | Frontend | Medium |
| HT-10 | Database Persistence | Backend DB | High |
| HT-11 | Error Handling | All | High |
| HT-12 | Clean Slate | Backend DB | Low |

### Minimum Verification

For a quick smoke test, complete at minimum:
- â˜ HT-1 (Server Startup)
- â˜ HT-2 (CLI Capture)
- â˜ HT-4 (API Direct Access)
- â˜ HT-8 (Hammer Benchmark)

### Full Verification

For complete confidence, run all tests HT-1 through HT-12.
