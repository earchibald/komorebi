# Komorebi: Comprehensive State of Implementation & Vision

**Date:** February 6, 2026  
**Version:** 0.7.0  
**Status:** Pre-1.0.0 Development ‚Äî Core systems production-ready, advanced features in pipeline  
**Compiled for:** Deep research agent brainstorming session

---

## Executive Summary

**Komorebi** is a cognitive infrastructure system designed to capture thoughts, extract meaning, and organize knowledge through recursive summarization and tool aggregation. It's a monolithic full-stack application combining a FastAPI backend, React frontend, and Model Context Protocol (MCP) server integration.

### Current State
- ‚úÖ **6 modules implemented** (v0.1‚Äìv0.7)
- ‚úÖ **30+ API endpoints** deployed and tested
- ‚úÖ **85 backend tests passing** with 3 skipped (MVP coverage gaps)
- ‚úÖ **True production-ready core**: Capture pipeline, dashboard, search, entity extraction
- ‚ö†Ô∏è **Partially implemented**: Recursive compaction (infrastructure ready, logic placeholder), MCP integration (registry built, no servers configured)
- üöß **Not yet started**: Docker deployment, bulk operations, advanced UI features

### Key Innovation: Signal Auto-Tracking Root Cause Fix
Recent work discovered and fixed critical bug in `@preact/signals-react` v2 integration. Signal `.value` reads require explicit auto-tracking import in `main.tsx` to enable reactivity. Without this, all reactive state changes silently failed ‚Äî root cause of months-old search/filter UI failures. **Fix: one-line import.** Documented as mandatory pattern in CONVENTIONS.md.

---

## Project Vision & Goals

### Phase 1: The Capture Problem
**Goal:** Build fast, non-blocking ingestion that never loses data.

**What we solved:**
- Sub-100ms API capture (returns immediately with 202 Accepted)
- Background processing via async task queue
- Real-time SSE updates to UI (<5ms delivery)
- Automatic status pipeline: `inbox` ‚Üí `processed` ‚Üí `compacted` ‚Üí `archived`

**Result:** Users can dump thoughts at typing speed; system processes silently.

### Phase 2: The Organization Problem  
**Goal:** Group related data and prevent context explosion.

**What we solved:**
- Project-based organization (chunks belong to projects)
- Recursive summarization via Map-Reduce pattern
- Compaction hooks infrastructure (ready for LLM wiring)
- Entity extraction pipeline (auto-cataloging structured data)

**Result:** Chunks don't disappear; they're progressively abstracted into summaries.

### Phase 3: The Discovery Problem  
**Goal:** Find what you've captured, even years later.

**What we solved:**
- Text search with LIKE queries (case-insensitive)
- Entity-based filtering (errors, URLs, tool IDs, decisions)
- Date range filtering
- Full-stack UI with SearchBar, FilterPanel, debounced API calls
- Related chunks discovery via TF-IDF cosine similarity
- Dashboard stats with weekly trends, insights, per-project breakdown

**Result:** Users can search, filter, and discover related context instantly.

### Phase 4: The Tool Aggregation Problem  
**Goal:** Integrate external tools (GitHub, filesystem, etc.) and capture their outputs as chunks.

**What we solved:**
- MCP (Model Context Protocol) client abstraction
- Declarative server configuration system (`config/mcp_servers.json`)
- Modular credential management (env vars, keyring)
- API infrastructure for calling tools
- "Tool Result ‚Üí Chunk" pipeline (partial)

**Result:** Komorebi becomes a universal tool aggregator; any tool output can become a chunk.

---

## Architecture Overview

### Technology Stack

| Layer | Technology | Version | Notes |
|-------|-----------|---------|-------|
| **Backend** | FastAPI | 0.100+ | Async-first, ASGI server |
| **Database** | SQLAlchemy (aiosqlite) | 2.0+ | Async ORM, swappable to PostgreSQL |
| **Frontend** | React + TypeScript | 18.2 + 5.3 | Vite build, Preact Signals for state |
| **State** | Preact Signals | 2.3.0 | Fine-grained reactivity without re-renders |
| **CLI** | Typer | 0.9+ | Beautiful CLI with Rich formatting |
| **Testing** | pytest + pytest-asyncio | Latest | 85 tests passing |
| **E2E** | Playwright | Latest | Browser automation for UI testing |
| **Linting** | Ruff | Latest | Single formatter/linter (22 active issues ‚Üí 0 in core) |
| **MCP** | Model Context Protocol | 2025-11-25 spec | Pluggable tool integration |

### System Architecture Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         FRONTEND (React 18.2 + Vite)            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Dashboard UI (6 tabs): Inbox, All, Dashboard, Timeline,  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Projects, MCP Tools                                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îÇ  SearchBar  ‚îÇ  FilterPanel ‚îÇ  ChunkList (tabs)        ‚îÇ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îÇ  (debounce) ‚îÇ  (6 filters) ‚îÇ  ‚Üí ChunkDrawer           ‚îÇ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îÇ             ‚îÇ              ‚îÇ  ‚Üí Stats/Timeline/MCPDash‚îÇ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  State: Preact Signals (chunks, searchResults,           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         timeline, relatedChunks, mcp.status, etc.)       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üï HTTP/SSE/WebSocket
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  BACKEND (FastAPI + SQLAlchemy)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ API Routes (30+ endpoints)                               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ /api/v1/chunks (CRUD + search + stats + timeline)    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ /api/v1/projects (CRUD + compact)                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ /api/v1/entities (list by chunk/project)            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ /api/v1/mcp (servers, tools, call)                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ /api/v1/sse (event stream)                           ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Business Logic Services                                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ CompactorService (Map-Reduce, recursive summ.)       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ MCPService (tool orchestration)                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ TFIDFService (similarity, related chunks)            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ EventBus (SSE broadcasting)                          ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Repository Layer (SQLAlchemy ORM)                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ ChunkRepository (list, search, timeline, stats)      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ ProjectRepository (tree-based hierarchy)             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ EntityRepository (bulk create, list by type)         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üï
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATABASE (SQLite aiosqlite)                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Tables:                                                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ chunks(id, content, summary, status, project_id)    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ projects(id, name, compaction_depth, last_compact)  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ entities(id, chunk_id, type, value, confidence)     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ mcp_server_configs(name, command, args, env)        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Indexes: chunk_id, project_id, entity_type, status      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             EXTERNAL INTEGRATIONS (MCP Servers)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Configured (disabled by default):                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ GitHub MCP (@modelcontextprotocol/server-github)     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ GitKraken MCP (@gitkraken/mcp-server-gitkraken)      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ Playwright MCP (@playwright/mcp)                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ Filesystem MCP (@modelcontextprotocol/server-fs)     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Pattern: Tool Output ‚Üí MCPService ‚Üí Chunk Capture       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow: Capture to Discovery

```
User Input
    ‚Üì
[CAPTURE] POST /chunks ‚Üí API receives, validates, returns 202 immediately
    ‚Üì
[QUEUE] Background task: process_chunk() via asyncio queue
    ‚Üì
[PROCESS] CompactorService.process_chunk():
  - Chunk status: inbox ‚Üí processed
  - Generate summary (currently placeholder, should use Ollama)
  - Extract entities (e.g., ERROR, URL, TOOL_ID)
  - Append to project context
  ‚Üì
[COMPACT] If project > 30KB:
  - Map: Summarize each PROCESSED chunk (e.g., "Fixed login bug")
  - Reduce: Summarize all summaries (e.g., "Login suite completed")
  - Status: chunks ‚Üí COMPACTED, project.compaction_depth++
  ‚Üì
[ARCHIVE] If chunk > 90 days old:
  - Chunk status: processed/compacted ‚Üí archived
  - Removes from default queries
  ‚Üì
[SEARCH] User queries:
  - Text search: LIKE on chunk.content + summary
  - Entity filter: EXISTS subquery on entities table
  - Date range: WHERE created_at BETWEEN x AND y
  - Results returned with pagination
  ‚Üì
[DISCOVER] Click chunk ‚Üí ChunkDrawer:
  - Full content, summary, tags, entities
  - Related chunks via TF-IDF similarity
  - Click related chunk ‚Üí navigate instantly
  ‚Üì
[INTEGRATE] Tool call (e.g., GitHub search):
  - MCPRegistry calls tool
  - Result captured as chunk (auto-tagged with tool name)
  - Indexed and searchable immediately
```

---

## Detailed Module Inventory

### Module 1: Core Capture Pipeline ‚úÖ (v0.1.0)
**Status:** Production-ready

**What's implemented:**
- `POST /api/v1/chunks` endpoint (fast capture, 202 response)
- Pydantic models: Chunk, ChunkCreate, ChunkUpdate
- ChunkRepository with async SQLAlchemy
- Background task queue (asyncio.Queue for MVP)
- Automatic status: `inbox` ‚Üí `processed`
- Tests: 15 passing

**Key stats:**
- Capture latency: <100ms
- Database write: <10ms
- No blocking; returns immediately

**Trade-offs:**
- asyncio.Queue not persistent (tasks lost on restart) ‚Äî acceptable for MVP, migrate to Celery/Redis in v2
- No end-to-end encryption (can add per-project keys later)

---

### Module 2: Project Organization & Entities ‚úÖ (v0.2.0)
**Status:** Production-ready

**What's implemented:**
- Projects table with compaction tracking
- POST/GET /api/v1/projects endpoints (CRUD)
- Entity extraction infrastructure (EntityRepository, EntityCreate schema)
- TF-IDF-based entity extraction (pure Python, zero external deps)
- 5 entity types: ERROR, URL, TOOL_ID, DECISION, CODE_REF
- JSON confidence scores (0.0‚Äì1.0)
- Tests: 12 passing

**Key features:**
- Chunks group by project
- Entity filtering via EXISTS subquery
- Per-entity context snippets (50 chars before/after)

**Trade-offs:**
- Entity confidence from simple word-matching heuristics (not ML)
- No automatic entity linking (can add in v1 with NLP)

---

### Module 3: MCP Aggregator ‚úÖ (v0.3.0)  
**Status:** Infrastructure production-ready, no servers configured

**What's implemented:**
- MCPClient class (stdio-based JSON-RPC 2.0)
- MCPRegistry with parallel server startup (5x faster)
- Declarative config system (`config/mcp_servers.json`)
- Modular credential management (env vars, keyring URIs)
- API: GET /mcp/servers, GET /mcp/tools, POST /mcp/{name}/{tool}/call
- Tool result ‚Üí chunk pipeline (partial)
- MCPPanel dashboard (real-time server status badges, tool browser)
- Tests: MCP hammer validated at 259 req/s

**Key features:**
- Supports any MCP server (GitHub, GitKraken, Playwright, Filesystem, custom)
- Secrets stored in environment (never hardcoded)
- Real-time status in UI
- Error recovery (partial)

**Known limitations:**
- No pre-configured servers (requires manual setup)
- No automatic retry logic
- No workflow UI for tool ‚Üí chunk capture

---

### Module 4: Search & Entity Filtering ‚úÖ (v0.4‚Äìv0.5)
**Status:** Production-ready

**What's implemented:**
- Backend: `GET /api/v1/chunks/search` with 7 parameters
  - Text search (LIKE, case-insensitive)
  - Entity type/value filters (EXISTS subquery)
  - Date range (created_after, created_before)
  - Pagination (limit, offset)
  - Project filter
- Frontend: SearchBar + FilterPanel components
  - 300ms debouncing
  - 6 advanced filters
  - Result count badge
  - Clear button
- ChunkList auto-switches between regular and search results
- Tests: 8 search tests + 6 filter tests (14/14 passing)

**Key stats:**
- Search latency: 50‚Äì100ms for 1000 chunks
- Debounced API calls prevent excessive load
- No relevance ranking (upgrade to FTS5 for v1)

**Trade-offs:**
- LIKE is O(n) ‚Äî scales to ~10k chunks, then needs FTS5
- No fuzzy matching (can add with LIKE % wildcards)
- Entity filtering tests skipped (entity creation MVP limitation)

---

### Module 5: Related Chunks (TF-IDF) ‚úÖ (v0.7.0)
**Status:** Production-ready

**What's implemented:**
- TFIDFService: Pure Python implementation
  - Tokenization with stopword filtering (3-char minimum)
  - Cosine similarity calculation
  - find_related() with configurable top_k
  - Shared term extraction
- API: `GET /api/v1/chunks/{id}/related` with similarity scores
- Frontend: Related chunks section in ChunkDrawer with badges
- Tests: 17 TF-IDF + API tests (all passing)

**Key features:**
- Zero external dependencies (no scikit-learn)
- Shared terms display (what makes chunks similar)
- Click-to-navigate between related chunks
- O(N) per request suitable for ‚â§10k chunks

**Trade-offs:**
- No personalization (all users see same related chunks)
- No weighting by user relevance
- No learning from user clicks

---

### Module 6: Dashboard, Timeline, Stats ‚úÖ (v0.7.0)
**Status:** Production-ready

**What's implemented:**
- Enhanced stats: `GET /api/v1/chunks/stats` with:
  - Weekly activity trends (buckets by day)
  - Insights (oldest inbox age, most active project, entity count)
  - Per-project breakdown
- Timeline: `GET /api/v1/chunks/timeline` with:
  - Granularity toggle (day/week/month)
  - Project filtering
  - Status breakdown per bucket
  - Time-series buckets
- Frontend components:
  - StatsDashboard: Weekly bar chart with insights panel
  - TimelineView: Granularity toggle, expandable buckets, colored segments
  - Inbox: Age indicators (üî¥>7d, üü°2-7d, üü¢<2d), sort toggle
  - ChunkDrawer: Related chunks, similarity badges, shared terms
  - Tab restructure: 6 tabs (Inbox, All, Dashboard, Timeline, Projects, MCP)
- Tests: 9 stats + 11 timeline + 17 related (37 total, all passing)

**Key features:**
- Weekly trends show activity patterns
- Inbox aging motivates processing
- Timeline shows project evolution
- Related chunks enable context jumping

---

### Module 5 (Proposed): Bulk Operations & Deployment üöß
**Status:** Designed, not implemented

**Planned features:**
- Bulk tag/archive/delete with undo (30-min window)
- Audit log (who did what when)
- Docker deployment bundle
- Railway.app target (persistent volume, auto-scaling)

**Design doc:** See PROPOSAL.md

---

## Test Coverage & Validation

### Backend Test Suite: 88 tests collected
```
‚úÖ 85 passed
‚è≠Ô∏è 3 skipped (MVP entity creation limitation)
‚ùå 0 failed

Breakdown by module:
‚îú‚îÄ Module 1 (Chunks): 15 tests
‚îú‚îÄ Module 2 (Projects/Entities): 12 + 6 = 18 tests
‚îú‚îÄ Module 3 (MCP): 3 tests
‚îú‚îÄ Module 4 (Search): 14 tests
‚îú‚îÄ Module 5 (Related/TF-IDF): 17 tests
‚îú‚îÄ Module 6 (Stats/Timeline): 9 + 11 = 20 tests
‚îî‚îÄ Module 1 (Ollama integration): 5 tests
```

### Frontend Testing
- TypeScript: Strict mode, zero errors
- Vite build: Passes cleanly
- Playwright E2E: 4 test specs for critical paths

### Performance Baseline
```
Component              Latency  Notes
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Chunk capture          <100ms   Returns 202 immediately
Process chunk          200‚Äì500ms Single LLM call for summary
Search 1000 chunks     50‚Äì100ms LIKE query, no indexing
Related chunks (TF-IDF) 100‚Äì200ms O(N) corpus comparison
Dashboard stats        50‚Äì100ms Weekly aggregation
Timeline generation    100‚Äì200ms Bucketing and filtering
```

### Stress Test Results
```
hammer_gen.py (500 chunks) ‚Üí 30 req/s, 0 failures
hammer_mcp.py (50 concurrent MCP calls) ‚Üí 259 req/s, 0 failures, 0 zombies
```

---

## Known Limitations & Trade-offs

### Phase 1: Not Yet Implemented

| Feature | Impact | Priority | Rationale |
|---------|--------|----------|-----------|
| **Ollama Integration** | Core logic missing | HIGH | Recursive summarization requires LLM |
| **Docker Deployment** | Can't scale beyond single machine | MEDIUM | Build artifact needed for Railway |
| **Bulk Operations** | No undo/archive workflow | MEDIUM | Users must delete one-by-one |
| **FTS5 Search** | Poor relevance for >10k chunks | MEDIUM | Use case for v1.0 |
| **MCP Server Config** | Servers not connected by default | MEDIUM | Requires manual setup in config.json |
| **Encryption at Rest** | No data protection | LOW | Add per-project keys in v1 |

### Phase 2: Blocked Dependencies

| Item | Blocker | Status |
|------|---------|--------|
| **Entity extraction accuracy** | Ollama availability | Design complete, waiting for Ollama |
| **Recursive compaction** | LLM summarization | Infrastructure ready, logic placeholder |
| **Tool result capture** | MCP servers configured | API ready, no test servers enabled |

### Phase 3: Scalability Notes

**Current limits:**
- SQLite: ~1 million chunks (single-file constraint)
- Search (LIKE): Sub-second for <10k chunks, degrading after
- TF-IDF: O(N) per request, suitable for <50k chunks
- Memory: ~500MB for 10k chunks in memory (all signals)
- Concurrent users: ~100 with single FastAPI worker (async)

**Migration paths:**
- SQLite ‚Üí PostgreSQL (swap `DATABASE_URL`, zero code changes thanks to SQLAlchemy)
- LIKE ‚Üí FTS5: Transparent upgrade (no breaking changes)
- LIKE ‚Üí Elasticsearch: Separate querypath (future)

---

## Code Patterns & Conventions

### Mandatory Patterns

0. **Git Commit Hygiene**: Commit frequently. No uncommitted files at end of session.
   ```bash
   git add <logically grouped files>
   git commit -m "type: Brief description"
   git push origin <branch>
   ```

1. **Signal Auto-Tracking Import** (Critical!)
   ```typescript
   // main.tsx ‚Äî MUST be first import
   import '@preact/signals-react/auto'  // Enable reactivity
   import React from 'react'
   ```
   Without this, `.value` reads have zero subscription effect.

2. **Signal-to-Input Bridge Pattern** (For controlled inputs)
   ```typescript
   function SearchBar() {
     const [localQuery, setLocalQuery] = useState('')
     
     // Sync FROM signal when external code resets
     useEffect(() => {
       setLocalQuery(searchQuery.value)
     }, [searchQuery.value])
     
     const handleChange = (e) => {
       setLocalQuery(e.target.value)      // Immediate UI
       searchQuery.value = e.target.value  // Update store
     }
   
     return <input value={localQuery} onChange={handleChange} />
   }
   ```
   Prevents `@preact/signals-react` race condition with React controlled inputs.

3. **Pydantic Create/Read/Update Split**
   ```python
   class ChunkCreate(BaseModel):
       content: str
       project_id: Optional[UUID] = None
   
   class ChunkUpdate(BaseModel):
       content: Optional[str] = None
       status: Optional[ChunkStatus] = None
   
   class Chunk(BaseModel):
       id: UUID
       content: str
       status: ChunkStatus
       created_at: str
   ```
   Enforces validation at each stage.

4. **Repository Pattern for Data Access**
   ```python
   class ChunkRepository:
       async def search(self, query: str, limit: int) -> tuple[list[Chunk], int]:
           # SQL query with LIKE
           # Return (results, total_count) for pagination
       
       async def list_by_status(self, status: ChunkStatus) -> list[Chunk]:
           # Simple filter
   ```
   Centralizes all database logic; no raw queries in endpoints.

5. **Async/await on all I/O**
   ```python
   async def process_chunk(self, chunk_id: UUID) -> None:
       chunk = await self.chunk_repo.get(chunk_id)
       summary = await self.ollama.summarize(chunk.content)  # Don't block
       await self.chunk_repo.update(chunk_id, summary=summary)
   ```
   Never use `time.sleep()` or blocking calls.

6. **TDD Red ‚Üí Green ‚Üí Refactor**
   ```bash
   # Red: Write failing tests
   pytest backend/tests/test_feature.py -v
   
   # Green: Implement minimal logic to pass
   pytest backend/tests/test_feature.py -v
   
   # Refactor: Clean up, document
   pytest backend/tests/test_feature.py -v
   ```
   All new features follow this workflow.

---

## Developer Experience & Tooling

### Prompts & Skills System (Agentic Governance)

**8 Custom Prompts** (full tool access):
1. `/implement-feature` ‚Äî Full-stack TDD (Standard tier)
2. `/write-tests` ‚Äî Test infrastructure (Standard tier)
3. `/debug-issue` ‚Äî 6-phase debugging (Premium tier)
4. `/architect-feature` ‚Äî Design & handoff (Premium tier)
5. `/refactor-code` ‚Äî Code improvement (Standard tier)
6. `/update-docs` ‚Äî Documentation sync (Economy tier)
7. `/review-pr` ‚Äî PR review workflow (Standard tier)
8. `/integrate-feature` ‚Äî Integration & versioning (Standard tier)

**4 Agent Skills**:
- `feature-implementer` (Standard) ‚Äî Scaffold generator with validation
- `code-formatter` (Economy) ‚Äî Ruff linting and formatting
- `deep-debugger` (Premium) ‚Äî Advanced async debugging
- `research-agent` (Research) ‚Äî Long-context analysis (Gemini)

**4 MCP Servers** (configured, most disabled by default):
- GitHub MCP: Repository operations, issues, PRs, code search
- GitKraken MCP: Advanced git workflows, visual diffs
- Playwright MCP: Browser automation, E2E testing
- Filesystem MCP: Sandboxed file read/write

### Documentation Suite
- `CURRENT_STATUS.md` ‚Äî What works right now
- `PROGRESS.md` ‚Äî Execution log by phase
- `CONVENTIONS.md` ‚Äî Code patterns and rules (750 lines)
- `BUILD.md` ‚Äî Quick start and architecture
- `PROPOSALMD` ‚Äî Module specifications (989 lines)
- `ELICITATIONS.md` ‚Äî Pending decisions with rationales
- `docs/CHANGELOG.md` ‚Äî Version history
- `docs/API_REFERENCE.md` ‚Äî Endpoint documentation
- Plus 10+ other guides (DEVELOPMENT_WORKFLOWS, PROMPT_GUIDE, etc.)

### Local Development
```bash
# Backend
python -m venv venv && source venv/bin/activate
pip install -e ".[dev]"
uvicorn backend.app.main:app --reload --port 8000

# Frontend
cd frontend && npm install && npm run dev

# Tests
pytest backend/tests/ -v
```

---

## Strategic Roadmap (Next 3-6 Months)

### v0.8.0 (Next Release)
- [ ] Ollama integration wired into CompactorService
- [ ] Real recursive summarization (not placeholder)
- [ ] Token counting with tiktoken
- [ ] Streaming support for long summaries

### v0.9.0 (Post-Ollama)
- [ ] Docker deployment bundle
- [ ] Railway.app deployment guide
- [ ] SQLite ‚Üí PostgreSQL migration path docs
- [ ] Bulk operations (tag/archive/delete + undo)

### v1.0.0 (Candidate Release)
- [ ] FTS5 full-text search (relevance ranking)
- [ ] MCP servers pre-configured (GitHub, Filesystem minimum)
- [ ] Tool result ‚Üí chunk workflow UI
- [ ] Encryption at rest (per-project keys)
- [ ] Offline-first sync (optional local-first mode)

### Post-1.0 (Moonshots)
- Multi-tenant SaaS deployment
- Mobile app (React Native)
- AI agent control plane ("run tasks autonomously")
- Federated knowledge graph (cross-instance search)
- Custom LLM fine-tuning on private data

---

## Key Open Questions for Research Phase

### User Research
1. **Capture velocity**: Do users want < 100ms capture, or can we prioritize accuracy?
2. **Summarization quality**: What's the acceptable false-positive rate for entity extraction?
3. **Search relevance**: Should we jump straight to FTS5, or is LIKE acceptable for <10k chunks?
4. **Related chunks**: TF-IDF similarity useful, or should we use vector embeddings?

### Technical Scalability
1. **Recursive compaction depth**: Is 3 levels (processed ‚Üí compact1 ‚Üí compact2) enough, or do we need N?
2. **Token window management**: Should we be smarter about context window usage?
3. **Search index strategy**: Standalone Elasticsearch, or embedded e.g., SQLite FTS5?
4. **Concurrency model**: AsyncIO sufficient, or should we consider async workers (Celery)?

### Business Model
1. **Self-hosted vs SaaS**: Should we optimize for both, or pick one?
2. **Pricing tiers**: Free tier limits? Pro features?
3. **Data formats**: Support imports from Obsidian, Roam, Notion?
4. **API for third parties**: Open public API, or private only?

### Competitive Landscape
1. **vs Logseq/Obsidian**: How do we position the LLM + search angle?
2. **vs Pinecone**: Do we need vector DB, or is TF-IDF + FTS5 enough?
3. **vs Linear CRM**: What unique angle do we have for knowledge management?

---

## Resources for Deep Research

### Architecture Docs
- [BUILD.md](BUILD.md) ‚Äî Technical blueprint
- [ARCHITECTURE_HANDOFF.md](ARCHITECTURE_HANDOFF.md) ‚Äî Deployment design
- [CONVENTIONS.md](CONVENTIONS.md) ‚Äî Code patterns (750 lines, definitive)
- [PROPOSAL.md](PROPOSAL.md) ‚Äî Module specifications (989 lines)

### Current State
- [CURRENT_STATUS.md](docs/CURRENT_STATUS.md) ‚Äî What works right now
- [PROGRESS.md](PROGRESS.md) ‚Äî Execution log (13 phases, 428 lines)
- [CHANGELOG.md](docs/CHANGELOG.md) ‚Äî Version history with detailed features

### Technical Details
- [docs/API_REFERENCE.md](docs/API_REFERENCE.md) ‚Äî Endpoint specifications
- [docs/DEVELOPMENT_WORKFLOWS.md](docs/DEVELOPMENT_WORKFLOWS.md) ‚Äî Dev process
- [docs/CONFIGURATION.md](docs/CONFIGURATION.md) ‚Äî Env var reference

### Decision Log
- [ELICITATIONS.md](ELICITATIONS.md) ‚Äî Open questions with rationale
- [VERSIONING.md](VERSIONING.md) ‚Äî Version governance rules

### Source Code Structure
```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/              # 30+ endpoints (chunks, projects, entities, mcp, sse)
‚îÇ   ‚îú‚îÄ‚îÄ core/             # Services (compactor, events, ollama_client, similarity)
‚îÇ   ‚îú‚îÄ‚îÄ db/               # Database layer (SQLAlchemy, repositories)
‚îÇ   ‚îú‚îÄ‚îÄ mcp/              # MCP client (auth, config, registry)
‚îÇ   ‚îú‚îÄ‚îÄ models/           # Pydantic schemas
‚îÇ   ‚îî‚îÄ‚îÄ services/         # Business logic (mcp_service)
‚îú‚îÄ‚îÄ tests/                # 85 passing tests
‚îî‚îÄ‚îÄ __init__.py

frontend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/       # 8+ React components
‚îÇ   ‚îú‚îÄ‚îÄ store/            # Preact Signals state
‚îÇ   ‚îî‚îÄ‚îÄ theme/            # CSS variables and styling
‚îî‚îÄ‚îÄ e2e/                  # Playwright tests

cli/
‚îî‚îÄ‚îÄ main.py               # Typer CLI (capture, list, search, etc.)

config/
‚îî‚îÄ‚îÄ mcp_servers.json      # MCP server declarations

scripts/
‚îú‚îÄ‚îÄ hammer_gen.py         # Stress testing (500 chunks)
‚îú‚îÄ‚îÄ hammer_mcp.py         # MCP stress testing (259 req/s)
‚îú‚îÄ‚îÄ migrate_module2.py    # Database migration
‚îî‚îÄ‚îÄ sync-versions.sh      # Version synchronization
```

---

## How to Use This Document

**For Research Agent:**
1. Read this omnibus overview (20 min)
2. Dive into PROPOSAL.md for Module 5+ ideas
3. Reference CONVENTIONS.md for proven patterns
4. Review PROGRESS.md for what took how long
5. Brainstorm improvements to architecture, scalability, UX

**For Implementers:**
1. Start with PROGRESS.md phase relevant to your task
2. Check CONVENTIONS.md for mandatory patterns
3. Use `/implement-feature` or `/debug-issue` prompts
4. Update PROGRESS.md and ELICITATIONS.md with decisions
5. Commit frequently with semantic messages

**For Users:**
1. See CURRENT_STATUS.md for what works
2. Try quick-start in BUILD.md
3. Explore GETTING_STARTED.md for first steps
4. Reference API_REFERENCE.md for endpoint details

---

**Document generated:** February 6, 2026  
**Version:** 0.7.0  
**Ready for:** Deep research brainstorming, strategic planning, next-phase design  
**Last updated:** Integration workflow completion (PR #1 ready)
